<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TeleEgo: Benchmarking Egocentric AI Assistants in the Wild</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary-color: #2563eb;
            --secondary-color: #7c3aed;
            --accent-color: #06b6d4;
            --dark-bg: #0f172a;
            --light-bg: #f8fafc;
            --text-dark: #1e293b;
            --text-light: #64748b;
            --card-shadow: 0 10px 40px rgba(0,0,0,0.1);
            --hover-shadow: 0 20px 60px rgba(37,99,235,0.15);
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            line-height: 1.7;
            color: var(--text-dark);
            background: var(--light-bg);
        }

        /* Hero Section */
        .hero {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 100px 20px 80px;
            position: relative;
            overflow: hidden;
        }

        .hero::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url('data:image/svg+xml,<svg width="100" height="100" xmlns="http://www.w3.org/2000/svg"><defs><pattern id="grid" width="100" height="100" patternUnits="userSpaceOnUse"><path d="M 100 0 L 0 0 0 100" fill="none" stroke="rgba(255,255,255,0.1)" stroke-width="1"/></pattern></defs><rect width="100%" height="100%" fill="url(%23grid)"/></svg>');
            opacity: 0.3;
        }

        .hero-content {
            max-width: 1200px;
            margin: 0 auto;
            position: relative;
            z-index: 1;
        }

        .hero h1 {
            font-size: 3.5em;
            font-weight: 800;
            margin-bottom: 20px;
            line-height: 1.2;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
            color: #ffffff;
        }

        .hero .subtitle {
            font-size: 1.4em;
            margin-bottom: 15px;
            font-weight: 500;
            color: #ffffff;
            opacity: 1;
        }

        .hero .description {
            font-size: 1.1em;
            max-width: 900px;
            margin: 30px auto;
            line-height: 1.8;
            color: #ffffff;
            opacity: 1;
        }

        .hero-badges {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin: 40px 0 30px;
            flex-wrap: wrap;
        }

        .badge {
            background: rgba(255,255,255,0.25);
            backdrop-filter: blur(10px);
            padding: 8px 20px;
            border-radius: 25px;
            font-size: 0.95em;
            border: 1px solid rgba(255,255,255,0.4);
            font-weight: 600;
            color: #ffffff;
        }

        .btn-group {
            display: flex;
            gap: 15px;
            justify-content: center;
            flex-wrap: wrap;
        }

        .btn {
            background: white;
            color: var(--primary-color);
            padding: 15px 35px;
            text-decoration: none;
            border-radius: 50px;
            font-weight: 700;
            display: inline-block;
            transition: all 0.3s;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            font-size: 1.05em;
        }

        .btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.3);
            background: rgba(255,255,255,0.95);
        }

        .btn-primary {
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: white;
        }

        .btn-primary:hover {
            background: linear-gradient(135deg, #1d4ed8, #6d28d9);
            transform: translateY(-3px);
        }

        /* Navigation */
        nav {
            background: white;
            box-shadow: 0 2px 20px rgba(0,0,0,0.08);
            position: sticky;
            top: 0;
            z-index: 100;
            backdrop-filter: blur(10px);
        }

        nav ul {
            list-style: none;
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            padding: 0;
        }

        nav li {
            margin: 0;
        }

        nav a {
            display: block;
            padding: 20px 25px;
            text-decoration: none;
            color: var(--text-dark);
            font-weight: 600;
            transition: all 0.3s;
            border-bottom: 3px solid transparent;
        }

        nav a:hover {
            color: var(--primary-color);
            border-bottom-color: var(--primary-color);
            background: rgba(37,99,235,0.05);
        }

        /* Container */
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Sections */
        section {
            padding: 100px 20px;
        }

        .alt-bg {
            background: white;
        }

        h2 {
            font-size: 2.8em;
            font-weight: 800;
            margin-bottom: 20px;
            text-align: center;
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        h3 {
            font-size: 2em;
            font-weight: 700;
            margin-bottom: 20px;
            color: var(--text-dark);
        }

        /* Feature Cards */
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin-top: 60px;
        }

        .feature-card {
            background: white;
            padding: 40px 30px;
            border-radius: 20px;
            box-shadow: var(--card-shadow);
            transition: all 0.3s;
            border: 1px solid rgba(37,99,235,0.1);
        }

        .feature-card:hover {
            transform: translateY(-10px);
            box-shadow: var(--hover-shadow);
        }

        .feature-icon {
            font-size: 3em;
            display: block;
            margin-bottom: 20px;
        }

        .feature-card h4 {
            font-size: 1.4em;
            margin-bottom: 15px;
            color: var(--primary-color);
            font-weight: 700;
        }

        .feature-card p {
            color: var(--text-light);
            line-height: 1.8;
        }

        /* Leaderboard */
        .leaderboard-section {
            margin: 60px 0;
        }

        .leaderboard-header {
            text-align: center;
            margin-bottom: 30px;
        }

        .leaderboard-header h3 {
            color: var(--primary-color);
            margin-bottom: 15px;
        }

        .leaderboard-description {
            font-size: 1.05em;
            color: var(--text-light);
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.6;
        }

        .table-caption {
            background: linear-gradient(135deg, rgba(37,99,235,0.1), rgba(124,58,237,0.1));
            padding: 20px;
            border-radius: 15px;
            margin-bottom: 20px;
            text-align: left;
        }

        .table-caption strong {
            color: var(--primary-color);
            font-size: 1.1em;
            display: block;
            margin-bottom: 10px;
        }

        .table-caption p {
            color: var(--text-dark);
            line-height: 1.8;
            margin: 8px 0;
        }

        .table-wrapper {
            overflow-x: auto;
            margin: 30px 0;
            border-radius: 15px;
            box-shadow: var(--card-shadow);
        }

        table {
            width: 100%;
            border-collapse: collapse;
            background: white;
            font-size: 0.95em;
        }

        thead {
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: white;
        }

        th {
            padding: 20px 15px;
            text-align: center;
            font-weight: 700;
            font-size: 0.95em;
        }

        th small {
            display: block;
            font-weight: 500;
            margin-top: 5px;
            opacity: 0.9;
        }

        td {
            padding: 18px 15px;
            text-align: center;
            border-bottom: 1px solid #e2e8f0;
        }

        tbody tr:hover {
            background: rgba(37,99,235,0.05);
        }

        .rank-1 {
            background: linear-gradient(to right, rgba(255,215,0,0.15), transparent);
        }

        .rank-2 {
            background: linear-gradient(to right, rgba(192,192,192,0.15), transparent);
        }

        .rank-3 {
            background: linear-gradient(to right, rgba(205,127,50,0.15), transparent);
        }

        .model-name {
            font-weight: 700;
            color: var(--primary-color);
            text-align: left;
        }

        /* Metrics */
        .metric-card {
            background: white;
            padding: 40px;
            border-radius: 20px;
            box-shadow: var(--card-shadow);
            margin: 40px 0;
            border-left: 5px solid var(--primary-color);
        }

        .metric-title {
            font-size: 1.8em;
            font-weight: 700;
            color: var(--primary-color);
            margin-bottom: 20px;
        }

        .metric-card p {
            color: var(--text-dark);
            line-height: 1.8;
            margin: 15px 0;
        }

        .metric-card ul {
            margin: 20px 0 20px 30px;
            color: var(--text-dark);
        }

        .metric-card li {
            margin: 10px 0;
            line-height: 1.8;
        }

        .mpt-notice {
            background: linear-gradient(135deg, rgba(251,191,36,0.1), rgba(245,158,11,0.1));
            border-left: 5px solid #f59e0b;
            padding: 30px;
            border-radius: 15px;
            margin: 40px 0;
        }

        .mpt-notice h4 {
            color: #d97706;
            font-size: 1.5em;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .mpt-notice p {
            color: var(--text-dark);
            line-height: 1.8;
            margin: 12px 0;
        }

        .mpt-notice strong {
            color: #d97706;
        }

        /* Timeline */
        .timeline {
            position: relative;
            padding: 40px 0;
        }

        .timeline::before {
            content: '';
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            width: 4px;
            height: 100%;
            background: linear-gradient(180deg, var(--primary-color), var(--secondary-color));
        }

        .timeline-item {
            display: flex;
            margin: 60px 0;
            position: relative;
        }

        .timeline-item:nth-child(odd) {
            flex-direction: row;
        }

        .timeline-item:nth-child(even) {
            flex-direction: row-reverse;
        }

        .timeline-content {
            width: 45%;
            background: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: var(--card-shadow);
            position: relative;
        }

        .timeline-item:nth-child(odd) .timeline-content {
            margin-right: auto;
        }

        .timeline-item:nth-child(even) .timeline-content {
            margin-left: auto;
        }

        .timeline-icon {
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            width: 50px;
            height: 50px;
            background: white;
            border: 4px solid var(--primary-color);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            box-shadow: 0 4px 15px rgba(37,99,235,0.3);
        }

        /* Dataset Stats */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 30px;
            margin: 60px 0;
        }

        .stat-card {
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: white;
            padding: 30px;
            border-radius: 15px;
            text-align: center;
            box-shadow: var(--card-shadow);
            transition: all 0.3s;
        }

        .stat-card:hover {
            transform: translateY(-5px) scale(1.02);
        }

        .stat-number {
            font-size: 3em;
            font-weight: 800;
            display: block;
            margin-bottom: 10px;
        }

        .stat-label {
            font-size: 1.1em;
            opacity: 0.95;
        }

        /* Citation */
        .citation-box {
            background: var(--dark-bg);
            color: #94a3b8;
            padding: 30px;
            border-radius: 15px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            margin: 30px 0;
        }

        .citation-box code {
            display: block;
            white-space: pre;
            font-size: 0.9em;
            line-height: 1.8;
        }

        /* Submit Section Styles */
        .submit-method {
            background: white;
            padding: 40px;
            border-radius: 20px;
            box-shadow: var(--card-shadow);
            margin: 40px 0;
            border-top: 5px solid var(--primary-color);
        }

        .submit-method h3 {
            color: var(--primary-color);
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 20px;
        }

        .method-icon {
            font-size: 1.8em;
        }

        .submit-steps {
            background: rgba(37,99,235,0.05);
            padding: 25px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .submit-steps ol {
            margin: 15px 0 0 25px;
            line-height: 2;
        }

        .submit-steps li {
            margin: 12px 0;
            color: var(--text-dark);
        }

        .submit-steps code {
            background: rgba(37,99,235,0.1);
            padding: 3px 8px;
            border-radius: 5px;
            font-family: 'Courier New', monospace;
            color: var(--primary-color);
            font-size: 0.9em;
        }

        .requirements-box {
            background: white;
            border: 2px solid var(--primary-color);
            border-radius: 15px;
            padding: 30px;
            margin: 30px 0;
        }

        .requirements-box h4 {
            color: var(--primary-color);
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .json-example {
            background: var(--dark-bg);
            color: #e2e8f0;
            padding: 25px;
            border-radius: 10px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 0.85em;
            line-height: 1.8;
            margin-top: 15px;
        }

        .json-key {
            color: #7dd3fc;
        }

        .json-string {
            color: #86efac;
        }

        .json-number {
            color: #818cf8;
        }

        .warning-box {
            background: #fef3c7;
            border-left: 4px solid #f59e0b;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .warning-box strong {
            color: #d97706;
        }

        /* Footer */
        footer {
            background: var(--dark-bg);
            color: white;
            padding: 60px 20px 30px;
            text-align: center;
        }

        footer h3 {
            color: white;
            margin-bottom: 30px;
        }

        .footer-links {
            list-style: none;
            margin: 30px 0;
        }

        .footer-links li {
            margin: 15px 0;
            font-size: 1.1em;
        }

        .footer-links a {
            color: var(--accent-color);
            text-decoration: none;
            transition: all 0.3s;
        }

        .footer-links a:hover {
            color: white;
            text-decoration: underline;
        }

        /* Animations */
        .fade-in {
            opacity: 0;
            transform: translateY(30px);
            transition: opacity 0.6s ease, transform 0.6s ease;
        }

        .fade-in.visible {
            opacity: 1;
            transform: translateY(0);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .hero h1 {
                font-size: 2.2em;
            }

            .hero .subtitle {
                font-size: 1.1em;
            }

            h2 {
                font-size: 2em;
            }

            .feature-grid {
                grid-template-columns: 1fr;
            }

            .timeline::before {
                left: 30px;
            }

            .timeline-icon {
                left: 30px;
                transform: none;
            }

            .timeline-content {
                width: calc(100% - 100px);
                margin-left: 100px !important;
                margin-right: 0 !important;
            }

            nav ul {
                flex-direction: column;
            }

            nav a {
                text-align: center;
            }
        }

        /* ========= Added: Force 4-up layout for scenarios grid ========= */
        .feature-grid.scenarios {
            display: grid;
            grid-template-columns: repeat(4, minmax(0, 1fr));
            gap: 30px;
        }

        @media (max-width: 1024px) {
            .feature-grid.scenarios {
                grid-template-columns: repeat(2, minmax(0, 1fr));
            }
        }

        @media (max-width: 768px) {
            .feature-grid.scenarios {
                grid-template-columns: 1fr;
            }
        }
        /* ======== End added styles ======== */
    </style>
</head>
<body>
    <!-- Hero Section -->
    <div class="hero">
        <div class="hero-content">
            <h1>TeleEgo Benchmark</h1>
            <div class="subtitle">Live-in-the-Wild Personal Assistant Benchmark</div>
            
            <div class="hero-badges">
                <span class="badge">üé• Egocentric Video</span>
                <span class="badge">üîä Multi-Modal Audio</span>
                <span class="badge">‚è±Ô∏è Real-Time Processing</span>
                <span class="badge">üß† Long-Term Memory</span>
            </div>

            <div class="btn-group">
                <a href="https://arxiv.org/abs/YOUR_PAPER_ID" class="btn" target="_blank">
                    üìÑ Paper
                </a>
                <a href="https://github.com/Programmergg/TeleEgo" class="btn" target="_blank">
                    üíª GitHub
                </a>
                <a href="https://huggingface.co/datasets/David0219/TeleEgo" class="btn" target="_blank">
                    ü§ó Dataset
                </a>
                <a href="https://seline02.github.io/2025/11/10/TeleEgo-%E6%B5%81%E5%BC%8F%E5%85%A8%E6%A8%A1%E6%80%81%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%E8%AF%84%E6%B5%8B%E5%9F%BA%E5%87%86/" class="btn" target="_blank">
                    üìù Blog (‰∏≠Êñá)
                </a>
            </div>
        </div>
    </div>

    <!-- Navigation -->
    <nav>
        <ul>
            <li><a href="#overview">Overview</a></li>
            <li><a href="#leaderboard">Leaderboard</a></li>
            <li><a href="#metrics">Evaluation</a></li>
            <li><a href="#dataset">Dataset</a></li>
            <li><a href="#submit">Submit</a></li>
            <li><a href="#citation">Citation</a></li>
        </ul>
    </nav>

    <!-- Overview Section -->
    <section id="overview">
        <div class="container">
            <h2>Why TeleEgo?</h2>
            <p style="text-align: center; max-width: 900px; margin: 0 auto 60px; font-size: 1.15em;">
                Existing benchmarks evaluate AI assistants on curated, short-duration clips. 
                <strong>TeleEgo</strong> challenges models with <strong>real-world, continuous streams</strong> 
                spanning hours of daily activities across diverse scenarios.
            </p>

            <div class="feature-grid">
                <div class="feature-card fade-in">
                    <span class="feature-icon">üåç</span>
                    <h4>Real-World Complexity</h4>
                    <p>Authentic egocentric recordings from real users performing daily activities across work, study, social, shopping, health, and travel scenarios.</p>
                </div>
                <div class="feature-card fade-in">
                    <span class="feature-icon">üé¨</span>
                    <h4>Streaming Protocol</h4>
                    <p>Questions arrive dynamically throughout the video stream, mimicking real personal assistant interactions without pre-segmentation.</p>
                </div>
                <div class="feature-card fade-in">
                    <span class="feature-icon">üß©</span>
                    <h4>Multi-Modal Integration</h4>
                    <p>Combines egocentric video, ambient audio, speech transcripts, and visual narrations requiring cross-modal reasoning.</p>
                </div>
                <div class="feature-card fade-in">
                    <span class="feature-icon">‚è≥</span>
                    <h4>Long-Horizon Memory</h4>
                    <p>Tests model's ability to retain and recall information across extended time periods, from seconds to hours.</p>
                </div>
                <div class="feature-card fade-in">
                    <span class="feature-icon">‚ö°</span>
                    <h4>Real-Time Constraints</h4>
                    <p>Models must respond within decision windows, reflecting the temporal demands of live assistance.</p>
                </div>
                <div class="feature-card fade-in">
                    <span class="feature-icon">üìä</span>
                    <h4>Verifiable Evidence</h4>
                    <p>Every answer requires precise temporal and modality grounding, enabling auditable evaluation.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Leaderboard Section -->
    <section id="leaderboard" class="alt-bg">
        <div class="container">
            <h2>Leaderboard</h2>
            <p style="text-align: center; max-width: 900px; margin: 0 auto 60px; font-size: 1.1em;">
                Comprehensive Real-Time Accuracy (RTA) evaluation results on TeleEgo benchmark. 
                Models are evaluated on a single participant's video under strict streaming protocol.
            </p>

            <!-- Table 3: Proprietary API Models -->
            <div class="leaderboard-section">
                <div class="table-caption fade-in">
                    <strong>Table 1: RTA results of proprietary MLLMs on TeleEgo (single-video evaluation)</strong>
                    <p>
                        GPT-4o and Gemini-2.5-Pro are evaluated via API calls with internal implementations opaque. 
                        Due to extensive video duration (~14 hours) and API latency, both models were evaluated on the same participant's video for fair comparison.
                    </p>
                    <p>
                        <strong>Key Observations:</strong> GPT-4o shows strong Understanding performance (66.67%), especially on Intent Inference (81.81%) and Causal Understanding (81.58%), 
                        leveraging its general-purpose reasoning. However, performance drops on Memory (42.18%) and Cross-Memory Reasoning (44.23%) where fine-grained temporal binding is critical.
                    </p>
                </div>

                <div class="table-wrapper fade-in">
                    <table>
                        <thead>
                            <tr>
                                <th rowspan="2">Method</th>
                                <th rowspan="2">Params</th>
                                <th rowspan="2">Omni</th>
                                <th rowspan="2">Streaming</th>
                                <th colspan="6">Memory (%)</th>
                                <th colspan="5">Understanding (%)</th>
                                <th colspan="4">Cross-Memory Reasoning (%)</th>
                                <th rowspan="2">Overall</th>
                            </tr>
                            <tr>
                                <th>UlM</th>
                                <th>StM</th>
                                <th>ET</th>
                                <th>TCI</th>
                                <th>LtM</th>
                                <th>All</th>
                                <th>II</th>
                                <th>CU</th>
                                <th>CmU</th>
                                <th>MsR</th>
                                <th>All</th>
                                <th>CeR</th>
                                <th>TCU</th>
                                <th>CtC</th>
                                <th>All</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="rank-1">
                                <td class="model-name">GPT-4o</td>
                                <td>-</td>
                                <td>‚úì</td>
                                <td>-</td>
                                <td>42.31</td>
                                <td>40.58</td>
                                <td>31.91</td>
                                <td>47.37</td>
                                <td>52.78</td>
                                <td>42.18</td>
                                <td>81.81</td>
                                <td>81.58</td>
                                <td>45.71</td>
                                <td>50.00</td>
                                <td>66.67</td>
                                <td>44.44</td>
                                <td>40.00</td>
                                <td>45.00</td>
                                <td>44.23</td>
                                <td>48.94</td>
                            </tr>
                            <tr class="rank-2">
                                <td class="model-name">Gemini-2.5-Pro</td>
                                <td>-</td>
                                <td>‚úì</td>
                                <td>-</td>
                                <td>49.04</td>
                                <td>45.59</td>
                                <td>34.04</td>
                                <td>47.37</td>
                                <td>44.44</td>
                                <td>45.05</td>
                                <td>63.64</td>
                                <td>55.26</td>
                                <td>37.14</td>
                                <td>28.57</td>
                                <td>48.03</td>
                                <td>40.74</td>
                                <td>40.00</td>
                                <td>45.00</td>
                                <td>42.31</td>
                                <td>45.55</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <!-- Table 4: Pseudo-streaming Open-source Models -->
            <div class="leaderboard-section">
                <div class="table-caption fade-in">
                    <strong>Table 2: RTA results of pseudo-streaming open-source MLLMs on TeleEgo</strong>
                    <p>
                        These models lack cross-call memory mechanisms and process each input unit independently. They are categorized as ‚Äúpseudo-streaming‚Äù because they do not natively support continuous streaming interaction. In our evaluation, we deliberately avoid supplying any uncompressed historical context to the models‚Äîotherwise, the burden of memory would be shifted to the context window rather than truly examining their intrinsic memory capability. Therefore, they are evaluated under a strict streaming protocol, ensuring that performance reflects the models‚Äô genuine ability to retain information over time. 
                    </p>
                    <p>
                        <strong>Key Observations:</strong> VideoChat-Online, Qwen2.5-VL, and Qwen2.5-Omni achieve manageable Understanding performance 
                        but struggle significantly on Memory and Cross-Memory Reasoning tasks. Among the three, Qwen2.5-Omni achieves the highest overall RTA (46.96%), 
                        primarily because it has stronger base model capabilities and avoids ASR transcription errors by directly processing audio.
                    </p>
                </div>

                <div class="table-wrapper fade-in">
                    <table>
                        <thead>
                            <tr>
                                <th rowspan="2">Method</th>
                                <th rowspan="2">Params</th>
                                <th rowspan="2">Omni</th>
                                <th rowspan="2">Streaming</th>
                                <th colspan="6">Memory (%)</th>
                                <th colspan="5">Understanding (%)</th>
                                <th colspan="4">Cross-Memory Reasoning (%)</th>
                                <th rowspan="2">Overall</th>
                            </tr>
                            <tr>
                                <th>UlM</th>
                                <th>StM</th>
                                <th>ET</th>
                                <th>TCI</th>
                                <th>LtM</th>
                                <th>All</th>
                                <th>II</th>
                                <th>CU</th>
                                <th>CmU</th>
                                <th>MsR</th>
                                <th>All</th>
                                <th>CeR</th>
                                <th>TCU</th>
                                <th>CtC</th>
                                <th>All</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="model-name">VideoChat-Online</td>
                                <td>4B</td>
                                <td>‚úó</td>
                                <td> </td>
                                <td>30.74</td>
                                <td>26.29</td>
                                <td>19.35</td>
                                <td>29.84</td>
                                <td>22.78</td>
                                <td>26.69</td>
                                <td>57.35</td>
                                <td>44.13</td>
                                <td>35.44</td>
                                <td>27.89</td>
                                <td>42.34</td>
                                <td>18.79</td>
                                <td>32.00</td>
                                <td>41.60</td>
                                <td>29.43</td>
                                <td>31.28</td>
                            </tr>
                            <tr>
                                <td class="model-name">Qwen2.5-VL</td>
                                <td>3B</td>
                                <td>‚úó</td>
                                <td>‚úó</td>
                                <td>45.42</td>
                                <td>42.01</td>
                                <td>31.18</td>
                                <td>37.90</td>
                                <td>33.33</td>
                                <td>39.66</td>
                                <td>66.35</td>
                                <td>53.99</td>
                                <td>47.57</td>
                                <td>41.50</td>
                                <td>53.28</td>
                                <td>32.89</td>
                                <td>48.00</td>
                                <td>52.00</td>
                                <td>42.14</td>
                                <td>43.67</td>
                            </tr>
                            <tr>
                                <td class="model-name">Qwen2.5-Omni</td>
                                <td>7B</td>
                                <td>‚úì</td>
                                <td> </td>
                                <td>44.21</td>
                                <td>42.75</td>
                                <td>35.48</td>
                                <td>41.13</td>
                                <td>37.97</td>
                                <td>41.20</td>
                                <td>72.51</td>
                                <td>61.50</td>
                                <td>50.00</td>
                                <td>48.98</td>
                                <td>59.07</td>
                                <td>37.58</td>
                                <td>56.00</td>
                                <td>61.60</td>
                                <td>49.16</td>
                                <td>46.96</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <!-- Table 5: MiniCPM-o with varying session lengths -->
            <div class="leaderboard-section">
                <div class="table-caption fade-in">
                    <strong>Table 3: RTA results of MiniCPM-o with varying session lengths on TeleEgo</strong>
                    <p>
                        MiniCPM-o is the only model in our study with an explicit streaming interface that accepts chunk-wise incremental input. 
                        However, it lacks dynamic memory management: the KV cache grows without compression, eviction, or sliding window, 
                        causing GPU memory overflow and attention dilution as video length increases.
                    </p>
                    <p>
                        <strong>Key Observations:</strong> RTA results indicate an optimal session length of about 1 minute (54.10% overall), 
                        with poorer performance at both shorter (50.60% at 1s) and longer intervals (30.15% at 10min). At longer intervals, 
                        the model often produces incoherent or off-topic responses, confirming that naive KV cache accumulation without memory management 
                        is insufficient for sustained streaming.
                    </p>
                </div>

                <div class="table-wrapper fade-in">
                    <table>
                        <thead>
                            <tr>
                                <th rowspan="2">Method</th>
                                <th rowspan="2">Params</th>
                                <th rowspan="2">Omni</th>
                                <th rowspan="2">Streaming</th>
                                <th rowspan="2">Session<br>Length</th>
                                <th colspan="6">Memory (%)</th>
                                <th colspan="5">Understanding (%)</th>
                                <th colspan="4">Cross-Memory Reasoning (%)</th>
                                <th rowspan="2">Overall</th>
                            </tr>
                            <tr>
                                <th>UlM</th>
                                <th>StM</th>
                                <th>ET</th>
                                <th>TCI</th>
                                <th>LtM</th>
                                <th>All</th>
                                <th>II</th>
                                <th>CU</th>
                                <th>CmU</th>
                                <th>MsR</th>
                                <th>All</th>
                                <th>CeR</th>
                                <th>TCU</th>
                                <th>CtC</th>
                                <th>All</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="model-name" rowspan="5">MiniCPM-o</td>
                                <td rowspan="5">8B</td>
                                <td rowspan="5">‚úì</td>
                                <td rowspan="5">‚úì</td>
                                <td>1sec</td>
                                <td>51.99</td>
                                <td>51.60</td>
                                <td>35.13</td>
                                <td>47.58</td>
                                <td>44.30</td>
                                <td>47.54</td>
                                <td>75.83</td>
                                <td>61.50</td>
                                <td>51.94</td>
                                <td>44.22</td>
                                <td>59.59</td>
                                <td>28.19</td>
                                <td>48.00</td>
                                <td>64.80</td>
                                <td>45.15</td>
                                <td>50.60</td>
                            </tr>
                            <tr>
                                <td>1min</td>
                                <td>50.60</td>
                                <td>55.53</td>
                                <td>37.28</td>
                                <td>53.63</td>
                                <td>51.05</td>
                                <td>50.11</td>
                                <td>80.57</td>
                                <td>69.48</td>
                                <td>56.80</td>
                                <td>51.02</td>
                                <td>65.64</td>
                                <td>33.56</td>
                                <td>36.00</td>
                                <td>66.40</td>
                                <td>47.49</td>
                                <td>54.10</td>
                            </tr>
                            <tr>
                                <td>3min</td>
                                <td>48.19</td>
                                <td>52.58</td>
                                <td>37.28</td>
                                <td>49.19</td>
                                <td>45.99</td>
                                <td>47.31</td>
                                <td>73.93</td>
                                <td>63.38</td>
                                <td>53.88</td>
                                <td>40.14</td>
                                <td>59.33</td>
                                <td>32.89</td>
                                <td>32.00</td>
                                <td>66.40</td>
                                <td>46.82</td>
                                <td>50.57</td>
                            </tr>
                            <tr>
                                <td>5min</td>
                                <td>43.00</td>
                                <td>44.23</td>
                                <td>33.69</td>
                                <td>47.58</td>
                                <td>37.55</td>
                                <td>41.71</td>
                                <td>63.51</td>
                                <td>56.34</td>
                                <td>44.17</td>
                                <td>43.54</td>
                                <td>52.64</td>
                                <td>23.49</td>
                                <td>32.00</td>
                                <td>56.80</td>
                                <td>38.13</td>
                                <td>44.34</td>
                            </tr>
                            <tr>
                                <td>10min</td>
                                <td>28.50</td>
                                <td>28.01</td>
                                <td>23.66</td>
                                <td>30.65</td>
                                <td>26.16</td>
                                <td>27.60</td>
                                <td>41.71</td>
                                <td>40.38</td>
                                <td>34.95</td>
                                <td>29.93</td>
                                <td>37.32</td>
                                <td>15.44</td>
                                <td>36.00</td>
                                <td>37.60</td>
                                <td>26.42</td>
                                <td>30.15</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <p style="text-align: center; margin-top: 40px; font-style: italic; color: var(--text-light);">
                <strong>Note:</strong> Columns are grouped into three capability blocks: Memory, Understanding, and Cross-Memory Reasoning, 
                with an "All" column summarizing each block and an "Overall" column aggregating across blocks. 
                "Omni" denotes integrated audio-video-text perception; "Streaming" denotes native support for streaming interaction. 
                A ‚úì indicates the capability is supported, ‚úó indicates not supported, and "-" indicates unknown.
            </p>
        </div>
    </section>

    <!-- Evaluation Metrics Section -->
    <section id="metrics">
        <div class="container">
            <h2>üìä Evaluation Metrics</h2>
            
            <div class="metric-card fade-in">
                <div class="metric-title">‚ö° Real-Time Accuracy (RTA)</div>
                <p>
                    <strong>RTA measures the percentage of questions answered correctly within a strict time window (5 seconds).</strong>
                    This metric simulates real-world scenarios where personal assistants must respond promptly.
                </p>
                <p>
                    Unlike traditional offline evaluation, RTA enforces temporal constraints:
                </p>
                <ul>
                    <li><strong>Decision Window:</strong> Models have only 5 seconds after question trigger to respond</li>
                    <li><strong>First-Attempt Only:</strong> Only the first response is evaluated (no retries)</li>
                    <li><strong>Streaming Protocol:</strong> Questions arrive dynamically throughout video playback</li>
                </ul>
                <p>
                    RTA is calculated as: <strong>(Questions answered correctly within time window) / (Total questions) √ó 100%</strong>
                </p>
            </div>

            <div class="metric-card fade-in">
                <div class="metric-title">üß† Memory Persistence Time (MPT)</div>
                <p>
                    <strong>MPT measures how long a model retains information after initially answering correctly.</strong>
                    For questions answered correctly at time t*, the system schedules recall tests at t* + Œî intervals (Œî = 60s, r = 1,2,...,10).
                </p>
                <p>
                    Key characteristics:
                </p>
                <ul>
                    <li><strong>No Evidence Replay:</strong> During recall, only current video stream is accessible (no re-showing of original evidence)</li>
                    <li><strong>Early Stopping:</strong> Once a recall test fails, subsequent tests are removed from the schedule</li>
                    <li><strong>MPT Calculation:</strong> Time from t* to first recall failure (capped at 600 seconds for models passing all 10 recalls)</li>
                </ul>
            </div>

            <!-- MPT Current Status Notice -->
            <div class="mpt-notice fade-in">
                <h4>‚ö†Ô∏è About MPT Evaluation Status</h4>
                <p>
                    <strong>Currently, we have not included MPT results in our evaluation tables.</strong> This is because MPT requires models to demonstrate 
                    <strong>genuine long-term memory capabilities</strong> - the ability to not only answer correctly when information first appears, 
                    but also retain and recall that information long after it has disappeared from the input stream.
                </p>
                <p>
                    <strong>Why current models are not suitable for MPT evaluation:</strong>
                </p>
                <ul>
                    <li><strong>Pseudo-streaming models</strong> (VideoChat-Online, Qwen2.5-VL, Qwen2.5-Omni): Each call is independent with no cross-call memory. 
                    If they answer correctly in both initial and recall phases, we cannot distinguish between "remembered" vs "guessed correctly twice".</li>
                    <li><strong>API models</strong> (GPT-4o, Gemini-2.5-Pro): Their internal implementations are black boxes. In our evaluation setup (without 
                    accumulating raw history), they face the same issue as pseudo-streaming models.</li>
                    <li><strong>Streaming model</strong> (MiniCPM-o): Although it supports streaming input and maintains KV cache across calls, we must manually 
                    reset sessions every few minutes to prevent memory overflow and generation quality degradation. This means if an initial test and its recall 
                    span across a session boundary, the model's memory is artificially cleared - making MPT measurements unreliable.</li>
                </ul>
                <p>
                    <strong>MPT is a forward-looking metric</strong> that aligns with TeleEgo's goal of evaluating realistic long-term egocentric assistants. 
                    We look forward to the emergence of models with true long-horizon streaming memory - rare few can run continuously for hours without resets 
                    while maintaining stable generation quality. <strong>We anticipate that future truly streaming MLLMs with dynamic memory management will enable 
                    meaningful MPT evaluation, providing critical insights into how long information is retained beyond the moment of first use.</strong>
                </p>
                <p style="margin-top: 20px; color: var(--primary-color); font-weight: 600;">
                    üöÄ TeleEgo, together with our released MPT evaluation framework and code, provides a unified setting to assess both real-time correctness 
                    and long-term memory persistence, paving the way for future work on practical egocentric AI assistants.
                </p>
            </div>

            <div class="metric-card fade-in">
                <div class="metric-title">üìã Task Categories</div>
                <p>
                    Questions are organized into three cognitive dimensions with 12 fine-grained subtasks:
                </p>
                <ul>
                    <li><strong>Memory (58.8% of questions):</strong> Ultra-long Memory, Short-term Memory, Long-term Memory, Entity Tracking, Temporal Comparison & Interval</li>
                    <li><strong>Understanding (27.3%):</strong> Intent Inference, Causal Understanding, Cross-modal Understanding, Multi-step Reasoning</li>
                    <li><strong>Cross-Memory Reasoning (13.9%):</strong> Cross-entity Relation, Temporal Chain Understanding, Cross-temporal Causality</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Dataset Section -->
    <section id="dataset" class="alt-bg">
        <div class="container">
            <h2>üìö Dataset</h2>
            
            <p style="text-align: center; max-width: 900px; margin: 0 auto 40px; font-size: 1.15em;">
                TeleEgo comprises <strong>70+ hours of continuous egocentric video</strong> from 5 diverse participants, 
                with <strong>3,291 manually annotated questions</strong> covering 12 cognitive tasks.
            </p>

            <div class="stats-grid fade-in">
                <div class="stat-card">
                    <span class="stat-number">5</span>
                    <span class="stat-label">Participants</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">70+</span>
                    <span class="stat-label">Hours of Video</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">3,291</span>
                    <span class="stat-label">QA Pairs</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">12</span>
                    <span class="stat-label">Task Categories</span>
                </div>
            </div>

            <h3 style="text-align: center; margin-top: 80px;">üìä Data Collection</h3>
            
            <div class="timeline">
                <div class="timeline-item">
                    <span class="timeline-icon">üìπ</span>
                    <div class="timeline-content fade-in">
                        <h4>Egocentric Video Capture</h4>
                        <p>
                            Participants wore first-person cameras continuously for 3 days, recording authentic daily activities 
                            across work, social, lifestyle, and cultural scenarios. Average video length: 14.4 hours per participant.
                        </p>
                    </div>
                </div>

                <div class="timeline-item">
                    <span class="timeline-icon">üîä</span>
                    <div class="timeline-content fade-in">
                        <h4>Multi-Modal Processing</h4>
                        <p>
                            Raw videos were processed to extract synchronized audio streams, speech transcripts via ASR, 
                            and visual narrations describing participant actions. All modalities are aligned to a unified timeline 
                            with millisecond precision.
                        </p>
                    </div>
                </div>

                <div class="timeline-item">
                    <span class="timeline-icon">‚úèÔ∏è</span>
                    <div class="timeline-content fade-in">
                        <h4>Question Annotation</h4>
                        <p>
                            Expert annotators generated 3,291 questions using GPT-4o for initial candidate generation, 
                            followed by rigorous human verification. Each question includes precise temporal grounding (evidence timestamps) 
                            and required modality information.
                        </p>
                    </div>
                </div>

                <div class="timeline-item">
                    <span class="timeline-icon">‚úÖ</span>
                    <div class="timeline-content fade-in">
                        <h4>Quality Control</h4>
                        <p>
                            Multiple rounds of quality checks ensure factual accuracy, temporal correctness, question clarity, 
                            and answer uniqueness. All personal identifiable information is removed or anonymized.
                        </p>
                    </div>
                </div>
            </div>

            <h3 style="text-align: center; margin-top: 80px;">üéØ Covered Scenarios</h3>
            
            <div class="feature-grid scenarios fade-in">
                <div class="feature-card">
                    <span class="feature-icon">üíº</span>
                    <h4>Work & Study</h4>
                    <p>Presentations, meetings, coding, studying, reception tasks</p>
                </div>
                <div class="feature-card">
                    <span class="feature-icon">üéÆ</span>
                    <h4>Social Activities</h4>
                    <p>Card games (UNO, Mahjong, Poker), video games, pool</p>
                </div>
                <div class="feature-card">
                    <span class="feature-icon">üè†</span>
                    <h4>Lifestyle & Routines</h4>
                    <p>Shopping, cooking, walking, fitness</p>
                </div>
                <div class="feature-card">
                    <span class="feature-icon">üçΩÔ∏è</span>
                    <h4>Outings & Culture</h4>
                    <p>Dining out, dating, museum visits</p>
                </div>
            </div>

            <div style="text-align: center; margin-top: 60px;">
                <a href="https://huggingface.co/datasets/David0219/TeleEgo" class="btn btn-primary" target="_blank">
                    ü§ó Download Dataset on Hugging Face
                </a>
            </div>
        </div>
    </section>

    <!-- Submit Section -->
    <section id="submit">
        <div class="container">
            <h2>üì§ Submit Your Results</h2>
            <p style="text-align: center; max-width: 900px; margin: 0 auto 60px; font-size: 1.1em;">
                We welcome submissions from all researchers! Submit your model's predictions to appear on the official leaderboard. 
                Choose your preferred submission method below.
            </p>

            <!-- Method 1: GitHub PR -->
            <div class="submit-method fade-in">
                <h3>
                    <span class="method-icon">üîÄ</span>
                    Method 1: GitHub Pull Request (Recommended)
                </h3>
                <p style="font-size: 1.05em; margin: 20px 0;">
                    Submit via GitHub PR for the fastest processing and automatic validation.
                </p>

                <div class="submit-steps">
                    <strong style="display: block; margin-bottom: 15px; font-size: 1.1em;">üìù Steps:</strong>
                    <ol>
                        <li>Fork the <a href="https://github.com/Programmergg/TeleEgo" target="_blank" style="color: var(--primary-color);">TeleEgo repository</a></li>
                        <li>Create a new folder under <code>submissions/</code> with format: <code>YYYY-MM-DD_YourModelName/</code></li>
                        <li>Add your submission files:
                            <ul style="margin-left: 30px; margin-top: 10px;">
                                <li><code>results.json</code> - Your model predictions</li>
                                <li><code>metadata.json</code> - Model information</li>
                                <li><code>README.md</code> - Brief description</li>
                            </ul>
                        </li>
                        <li>Create a pull request with title: <code>[Submission] YourModelName</code></li>
                        <li>Our team will review and merge within 3-5 business days</li>
                    </ol>
                </div>

                <div class="btn-group" style="margin-top: 25px;">
                    <a href="https://github.com/Programmergg/TeleEgo/fork" class="btn btn-primary" target="_blank">
                        üç¥ Fork Repository
                    </a>
                    <a href="https://github.com/Programmergg/TeleEgo/tree/main/submissions" class="btn" target="_blank">
                        üìÇ View Example Submissions
                    </a>
                </div>
            </div>

            <!-- Method 2: GitHub Issue -->
            <div class="submit-method fade-in">
                <h3>
                    <span class="method-icon">üí¨</span>
                    Method 2: GitHub Issue
                </h3>
                <p style="font-size: 1.05em; margin: 20px 0;">
                    For quick submissions or if you're unable to create a pull request, you can submit via GitHub Issues.
                </p>

                <div class="submit-steps">
                    <strong style="display: block; margin-bottom: 15px; font-size: 1.1em;">üìù Steps:</strong>
                    <ol>
                        <li>Go to our <a href="https://github.com/Programmergg/TeleEgo/issues" target="_blank" style="color: var(--primary-color);">Issues page</a></li>
                        <li>Click "New Issue" and select the "Submission" template</li>
                        <li>Fill in all required information in the template</li>
                        <li>Attach your <code>results.json</code> and <code>metadata.json</code> files</li>
                        <li>Submit the issue and we'll process your submission</li>
                    </ol>
                </div>

                <div class="btn-group" style="margin-top: 25px;">
                    <a href="https://github.com/Programmergg/TeleEgo/issues/new?template=submission.md" class="btn btn-primary" target="_blank">
                        ‚úâÔ∏è Create Submission Issue
                    </a>
                </div>
            </div>

            <!-- Method 3: Email -->
            <div class="submit-method fade-in">
                <h3>
                    <span class="method-icon">üìß</span>
                    Method 3: Email Submission
                </h3>
                <p style="font-size: 1.05em; margin: 20px 0;">
                    If GitHub is not accessible, you can email your submission directly to our team.
                </p>

                <div class="submit-steps">
                    <strong style="display: block; margin-bottom: 15px; font-size: 1.1em;">üìù Steps:</strong>
                    <ol>
                        <li>Prepare your submission files as a ZIP archive</li>
                        <li>Include all required files: <code>results.json</code>, <code>metadata.json</code>, <code>README.md</code></li>
                        <li>Email to: <a href="mailto:teleego.benchmark@gmail.com" style="color: var(--primary-color); font-weight: 600;">teleego.benchmark@gmail.com</a></li>
                        <li>Use subject line: <code>[TeleEgo Submission] Your Model Name</code></li>
                        <li>We'll confirm receipt within 48 hours</li>
                    </ol>
                </div>

                <div class="warning-box">
                    <strong>‚ö†Ô∏è Note:</strong> Email submissions may take longer to process than GitHub submissions. 
                    Please allow 5-7 business days for review.
                </div>
            </div>

            <!-- JSON Format Specifications -->
            <h3 style="text-align: center; margin-top: 80px; margin-bottom: 30px;">üìÑ Submission Format</h3>
            
            <div class="requirements-box">
                <h4>results.json Format:</h4>
                <p style="margin-bottom: 15px;">Your prediction results for each question in the test set.</p>
                <div class="json-example">
{
  <span class="json-key">"submission_info"</span>: {
    <span class="json-key">"model_name"</span>: <span class="json-string">"YourModel-v1.0"</span>,
    <span class="json-key">"submission_date"</span>: <span class="json-string">"2025-01-15"</span>,
    <span class="json-key">"team"</span>: <span class="json-string">"Your Organization"</span>
  },
  <span class="json-key">"predictions"</span>: [
    {
      <span class="json-key">"question_id"</span>: <span class="json-string">"Q001"</span>,
      <span class="json-key">"answer"</span>: <span class="json-string">"Your model's answer"</span>,
      <span class="json-key">"response_time"</span>: <span class="json-number">2.5</span>,
      <span class="json-key">"evidence_spans"</span>: [
        {
          <span class="json-key">"modality"</span>: <span class="json-string">"video"</span>
        }
      ]
    }
  ]
}
                </div>
            </div>

            <div class="requirements-box" style="margin-top: 30px;">
                <h4>metadata.json Format:</h4>
                <p style="margin-bottom: 15px;">Information about your model and experimental setup.</p>
                <div class="json-example">
{
  <span class="json-key">"model_name"</span>: <span class="json-string">"YourModel-v1.0"</span>,
  <span class="json-key">"organization"</span>: <span class="json-string">"Your Organization"</span>,
  <span class="json-key">"authors"</span>: [<span class="json-string">"Author 1"</span>, <span class="json-string">"Author 2"</span>],
  <span class="json-key">"contact_email"</span>: <span class="json-string">"your.email@example.com"</span>,
  <span class="json-key">"paper_url"</span>: <span class="json-string">"https://arxiv.org/abs/..."</span>,
  <span class="json-key">"code_url"</span>: <span class="json-string">"https://github.com/..."</span>,
  <span class="json-key">"model_description"</span>: <span class="json-string">"Brief description of your approach"</span>,
  <span class="json-key">"model_parameters"</span>: <span class="json-string">"7B"</span>,
  <span class="json-key">"training_data"</span>: <span class="json-string">"Description of training data used"</span>,
  <span class="json-key">"modalities_used"</span>: [<span class="json-string">"video"</span>, <span class="json-string">"audio"</span>, <span class="json-string">"text"</span>],
  <span class="json-key">"inference_time"</span>: <span class="json-string">"Average time per question"</span>
}
                </div>
            </div>

            <div class="warning-box" style="margin-top: 40px;">
                <strong>‚ö†Ô∏è Important Guidelines:</strong>
                <ul style="margin-top: 15px; margin-left: 20px; line-height: 2;">
                    <li>Ensure your results are reproducible</li>
                    <li>Do not use the test set for training or hyperparameter tuning</li>
                    <li>Provide complete information in metadata.json</li>
                    <li>Include evidence spans for all predictions when possible</li>
                    <li>Follow the exact JSON format specified above</li>
                </ul>
            </div>

            <div style="text-align: center; margin-top: 60px; padding: 40px; background: linear-gradient(135deg, rgba(37,99,235,0.1), rgba(124,58,237,0.1)); border-radius: 20px;">
                <h3 style="color: var(--primary-color); margin-bottom: 20px;">Need Help?</h3>
                <p style="font-size: 1.1em; margin-bottom: 25px;">
                    If you have questions about the submission process, please:
                </p>
                <div class="btn-group">
                    <a href="https://github.com/Programmergg/TeleEgo/issues" class="btn" target="_blank">
                        üí¨ Ask on GitHub
                    </a>
                    <a href="mailto:chengxuyuangg@gmail.com" class="btn">
                        üìß Email Us
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- Citation -->
    <section id="citation" class="alt-bg">
        <div class="container">
            <h2>Citation</h2>
            <p style="text-align: center; max-width: 800px; margin: 0 auto 40px; font-size: 1.1em;">
                If you find TeleEgo useful in your research, please cite our paper:
            </p>

            <div class="citation-box fade-in">
<code>
    @misc{yan2025teleegobenchmarkingegocentricai,
      title={TeleEgo: Benchmarking Egocentric AI Assistants in the Wild}, 
      author={Jiaqi Yan and Ruilong Ren and Jingren Liu and Shuning Xu and Ling Wang and Yiheng Wang and Yun Wang and Long Zhang and Xiangyu Chen and Changzhi Sun and Jixiang Luo and Dell Zhang and Hao Sun and Chi Zhang and Xuelong Li},
      year={2025},
      eprint={2510.23981},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.23981}, 

    }
</code>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container">
            <ul class="footer-links">
                <li>üìß Email: <a href="mailto:chengxuyuangg@gmail.com">teleego.benchmark@gmail.com</a></li>
                <li>üí¨ GitHub Issues: <a href="https://github.com/Programmergg/TeleEgo/issues" target="_blank">Report Issues</a></li>
            </ul>
            <p style="margin-top: 40px;">¬© 2025 TeleEgo Benchmark. All rights reserved.</p>
            <p>Developed and maintained by <a href="https://github.com/Tele-AI" target="_blank">TeleAI.</a></p>
        </div>
    </footer>

    <script>
        // Fade-in animation on scroll
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        }, observerOptions);

        document.querySelectorAll('.fade-in').forEach(el => observer.observe(el));

        // Smooth scroll for navigation links
        document.querySelectorAll('nav a').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const targetId = this.getAttribute('href');
                const targetSection = document.querySelector(targetId);
                if (targetSection) {
                    targetSection.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>